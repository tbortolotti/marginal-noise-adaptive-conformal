{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../third_party\")\n",
    "\n",
    "\n",
    "from cln import data\n",
    "from cln import contamination\n",
    "from cln.utils import evaluate_predictions, estimate_rho\n",
    "\n",
    "from cln.classification import MarginalLabelNoiseConformal\n",
    "from cln.classification_label_conditional import LabelNoiseConformal\n",
    "\n",
    "from third_party import arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default parameters\n",
    "exp_num = 1\n",
    "data_name = 'synthetic1'\n",
    "num_var = 20\n",
    "K = 4\n",
    "signal = 1\n",
    "model_name = 'SVC'\n",
    "epsilon = 0.1\n",
    "nu = 0\n",
    "contamination_model = \"uniform\"\n",
    "n_train = 5000\n",
    "n_cal = 1000\n",
    "estimate = \"none\"\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define other constant parameters\n",
    "n_test = 2000\n",
    "batch_size = 10\n",
    "allow_empty = True\n",
    "asymptotic_h_start = 1/400\n",
    "asymptotic_MC_samples = 10000\n",
    "\n",
    "# Initialize the data distribution\n",
    "if data_name == \"synthetic1\":\n",
    "    data_distribution = data.DataModel_1(K, num_var, signal=signal, random_state=seed)\n",
    "elif data_name == \"synthetic2\":\n",
    "    data_distribution = data.DataModel_2(K, num_var, signal=signal, random_state=seed)\n",
    "elif data_name == \"synthetic3\":\n",
    "    data_distribution = data.DataModel_3(K, num_var, signal=signal, random_state=seed)\n",
    "else:\n",
    "    print(\"Unknown data distribution!\")\n",
    "    sys.stdout.flush()\n",
    "    exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the label proportions from the population model\n",
    "rho = data_distribution.estimate_rho()\n",
    "\n",
    "# Initialize noise contamination process\n",
    "if contamination_model == \"uniform\":\n",
    "    T = contamination.construct_T_matrix_simple(K, epsilon)\n",
    "    M = contamination.convert_T_to_M(T,rho)\n",
    "elif contamination_model == \"block\":\n",
    "    T = contamination.construct_T_matrix_block(K, epsilon)\n",
    "    M = contamination.convert_T_to_M(T,rho)\n",
    "elif contamination_model == \"RRB\":\n",
    "    T = contamination.construct_T_matrix_block_RR(K, epsilon, nu)\n",
    "    M = contamination.convert_T_to_M(T,rho)\n",
    "elif contamination_model == \"random\":\n",
    "    T = contamination.construct_T_matrix_random(K, epsilon, random_state=seed)\n",
    "    M = contamination.convert_T_to_M(T,rho)\n",
    "else:\n",
    "    print(\"Unknown contamination model!\")\n",
    "    sys.stdout.flush()\n",
    "    exit(-1)\n",
    "\n",
    "# Compute the contaminated label proportions\n",
    "rho_tilde = np.dot(T, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize black-box model\n",
    "if model_name == 'RFC':\n",
    "    black_box = arc.black_boxes.RFC(n_estimators=100, max_features=\"sqrt\")\n",
    "elif model_name == 'SVC':\n",
    "    black_box = arc.black_boxes.SVC(clip_proba_factor = 1e-5)\n",
    "elif model_name == 'NN':\n",
    "    black_box = arc.black_boxes.NNet(max_iter=100)\n",
    "else:\n",
    "    print(\"Unknown model!\")\n",
    "    sys.stdout.flush()\n",
    "    exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Generate a large data set\\nprint(\"\\nGenerating data...\", end=\\' \\')\\nsys.stdout.flush()\\ndata_distribution.set_seed(1)\\nX_all, Y_all = data_distribution.sample(n_train+n_cal+n_test)\\nprint(\"Done.\")\\nsys.stdout.flush()\\n# Separate the test set\\nX, X_test, Y, Y_test = train_test_split(X_all, Y_all, test_size=n_test, random_state=2)\\n\\n# Generate the contaminated labels\\nprint(\"Generating contaminated labels...\", end=\\' \\')\\nsys.stdout.flush()\\ncontamination_process = contamination.LinearContaminationModel(T, random_state=3)\\nYt = contamination_process.sample_labels(Y)\\nprint(\"Done.\")\\nsys.stdout.flush()\\n\\n# Apply standard method to corrupted labels (for training)\\nprint(\"Training the predictive model...\", end=\\' \\')\\nsys.stdout.flush()\\nmethod_train = arc.methods.SplitConformal(X, Yt, black_box, K, 0.1, n_cal=n_cal, random_state=4)\\nprint(\"Done.\")\\nsys.stdout.flush()\\n\\n# Extract the pre-trained model\\nblack_box_pt = method_train.black_box\\n\\n# Separate the training e calibration set\\nX_train, X_cal, Y_train, Y_cal = train_test_split(X, Y, test_size=n_cal, random_state=5)\\n# Estimate the label contamination process\\np_hat_cal = black_box_pt.predict_proba(X_cal)\\nif not isinstance(p_hat_cal, np.ndarray):\\n    p_hat_cal = np.asarray(p_hat_cal)\\n_, K_out = p_hat_cal.shape\\nassert K_out == K, f\"black_box_pt returned {K_out} classes, expected {K}\"\\n# Estimate the contamination process using anchor points\\nT_hat = np.zeros((K, K), dtype=float)\\nx_bar_list = []\\n\\n# Loop over classes l in {0, ..., K-1}\\nfor l in range(K):\\n    # 1) Find x_bar^l = argmax_x p_hat(tilde{y}=l | x)\\n    #    This is the index in X_cal where class l has maximum probability\\n    idx_star = np.argmax(p_hat_cal[:, l])\\n    x_bar_l = X_cal[idx_star]\\n\\n    # 2) T_hat_{k,l} = p_hat(tilde{y}=k | x_bar^l)\\n    #    This is simply the probability vector at that index\\n    T_hat[:, l] = p_hat_cal[idx_star, :]\\n\\n    x_bar_list.append(x_bar_l)\\n# Alternative method\\ngamma = 0.005\\nif not (0 < gamma <= 1):\\n    raise ValueError(\"gamma must be in (0, 1].\")\\n\\n# Number of points to keep per class\\nm = max(1, int(np.ceil(gamma * n_cal)))\\n\\nT_hat_gamma = np.zeros((K, K), dtype=float)\\nA_indices_list = []\\n\\nfor l in range(K):\\n    # Scores for class l\\n    scores_l = p_hat_cal[:, l]\\n\\n    # Indices of top-m scores for class l\\n    top_idx = np.argsort(scores_l)[::-1][:m]\\n\\n    # Indexes with scores between the 85th and the 90th quantile\\n    # low_q  = np.quantile(scores_l, 0.9)\\n    # high_q = np.quantile(scores_l, 0.95)\\n    # idx_between = np.where((scores_l >= low_q) & (scores_l <= high_q))[0]\\n\\n    # Average the predicted probability vectors over these top examples\\n    T_hat_gamma[:, l] = p_hat_cal[top_idx, :].mean(axis=0)\\n\\n    A_indices_list.append(top_idx)\\n\\nprint(T)\\n\\nprint(T_hat)\\n\\nprint(T_hat_gamma)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Generate a large data set\n",
    "print(\"\\nGenerating data...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "data_distribution.set_seed(1)\n",
    "X_all, Y_all = data_distribution.sample(n_train+n_cal+n_test)\n",
    "print(\"Done.\")\n",
    "sys.stdout.flush()\n",
    "# Separate the test set\n",
    "X, X_test, Y, Y_test = train_test_split(X_all, Y_all, test_size=n_test, random_state=2)\n",
    "\n",
    "# Generate the contaminated labels\n",
    "print(\"Generating contaminated labels...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "contamination_process = contamination.LinearContaminationModel(T, random_state=3)\n",
    "Yt = contamination_process.sample_labels(Y)\n",
    "print(\"Done.\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Apply standard method to corrupted labels (for training)\n",
    "print(\"Training the predictive model...\", end=' ')\n",
    "sys.stdout.flush()\n",
    "method_train = arc.methods.SplitConformal(X, Yt, black_box, K, 0.1, n_cal=n_cal, random_state=4)\n",
    "print(\"Done.\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Extract the pre-trained model\n",
    "black_box_pt = method_train.black_box\n",
    "\n",
    "# Separate the training e calibration set\n",
    "X_train, X_cal, Y_train, Y_cal = train_test_split(X, Y, test_size=n_cal, random_state=5)\n",
    "# Estimate the label contamination process\n",
    "p_hat_cal = black_box_pt.predict_proba(X_cal)\n",
    "if not isinstance(p_hat_cal, np.ndarray):\n",
    "    p_hat_cal = np.asarray(p_hat_cal)\n",
    "_, K_out = p_hat_cal.shape\n",
    "assert K_out == K, f\"black_box_pt returned {K_out} classes, expected {K}\"\n",
    "# Estimate the contamination process using anchor points\n",
    "T_hat = np.zeros((K, K), dtype=float)\n",
    "x_bar_list = []\n",
    "\n",
    "# Loop over classes l in {0, ..., K-1}\n",
    "for l in range(K):\n",
    "    # 1) Find x_bar^l = argmax_x p_hat(tilde{y}=l | x)\n",
    "    #    This is the index in X_cal where class l has maximum probability\n",
    "    idx_star = np.argmax(p_hat_cal[:, l])\n",
    "    x_bar_l = X_cal[idx_star]\n",
    "\n",
    "    # 2) T_hat_{k,l} = p_hat(tilde{y}=k | x_bar^l)\n",
    "    #    This is simply the probability vector at that index\n",
    "    T_hat[:, l] = p_hat_cal[idx_star, :]\n",
    "\n",
    "    x_bar_list.append(x_bar_l)\n",
    "# Alternative method\n",
    "gamma = 0.005\n",
    "if not (0 < gamma <= 1):\n",
    "    raise ValueError(\"gamma must be in (0, 1].\")\n",
    "\n",
    "# Number of points to keep per class\n",
    "m = max(1, int(np.ceil(gamma * n_cal)))\n",
    "\n",
    "T_hat_gamma = np.zeros((K, K), dtype=float)\n",
    "A_indices_list = []\n",
    "\n",
    "for l in range(K):\n",
    "    # Scores for class l\n",
    "    scores_l = p_hat_cal[:, l]\n",
    "\n",
    "    # Indices of top-m scores for class l\n",
    "    top_idx = np.argsort(scores_l)[::-1][:m]\n",
    "\n",
    "    # Indexes with scores between the 85th and the 90th quantile\n",
    "    # low_q  = np.quantile(scores_l, 0.9)\n",
    "    # high_q = np.quantile(scores_l, 0.95)\n",
    "    # idx_between = np.where((scores_l >= low_q) & (scores_l <= high_q))[0]\n",
    "\n",
    "    # Average the predicted probability vectors over these top examples\n",
    "    T_hat_gamma[:, l] = p_hat_cal[top_idx, :].mean(axis=0)\n",
    "\n",
    "    A_indices_list.append(top_idx)\n",
    "\n",
    "print(T)\n",
    "\n",
    "print(T_hat)\n",
    "\n",
    "print(T_hat_gamma)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file: results/exp1/synthetic1_p20_K4_signal1_SVC_eps0.1_nu0_uniform_nt5000_nc1000_estnone_seed1.\n"
     ]
    }
   ],
   "source": [
    "# Add important parameters to table of results\n",
    "header = pd.DataFrame({'data':[data_name], 'num_var':[num_var], 'K':[K],\n",
    "                       'signal':[signal], 'n_train':[n_train], 'n_cal':[n_cal],\n",
    "                       'epsilon':[epsilon], 'nu':[nu], 'contamination':[contamination_model],\n",
    "                       'model_name':[model_name], 'estimate':[estimate], 'seed':[seed]})\n",
    "\n",
    "# Output file\n",
    "outfile_prefix = \"exp\"+str(exp_num) + \"/\" + data_name + \"_p\" + str(num_var)\n",
    "outfile_prefix += \"_K\" + str(K) + \"_signal\" + str(signal) + \"_\" + model_name\n",
    "outfile_prefix += \"_eps\" + str(epsilon) + \"_nu\" + str(nu) + \"_\" + contamination_model\n",
    "outfile_prefix += \"_nt\" + str(n_train) + \"_nc\" + str(n_cal) + \"_est\" + estimate + \"_seed\" + str(seed)\n",
    "print(\"Output file: {:s}.\".format(\"results/\"+outfile_prefix), end=\"\\n\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Describe the experiment\n",
    "def run_experiment(random_state):\n",
    "    print(\"\\nRunning experiment in batch {:d}...\".format(random_state))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Generate a large data set\n",
    "    print(\"\\nGenerating data...\", end=' ')\n",
    "    sys.stdout.flush()\n",
    "    data_distribution.set_seed(random_state+1)\n",
    "    X_all, Y_all = data_distribution.sample(n_train+n_cal+n_test)\n",
    "    print(\"Done.\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Separate the test set\n",
    "    X, X_test, Y, Y_test = train_test_split(X_all, Y_all, test_size=n_test, random_state=random_state+2)\n",
    "\n",
    "    # Generate the contaminated labels\n",
    "    print(\"Generating contaminated labels...\", end=' ')\n",
    "    sys.stdout.flush()\n",
    "    contamination_process = contamination.LinearContaminationModel(T, random_state=random_state+3)\n",
    "    Yt = contamination_process.sample_labels(Y)\n",
    "    print(\"Done.\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Estimate (if applicable) the label contamination model\n",
    "    if estimate==\"none\":\n",
    "        rho_tilde_hat = rho_tilde\n",
    "    elif estimate==\"rho\":\n",
    "        rho_tilde_hat = estimate_rho(Yt, K)\n",
    "    else:\n",
    "        print(\"Unknown estimation option!\")\n",
    "        sys.stdout.flush()\n",
    "        exit(-1)\n",
    "\n",
    "\n",
    "    # Apply standard method to corrupted labels (for training)\n",
    "    print(\"Training the predictive model...\", end=' ')\n",
    "    sys.stdout.flush()\n",
    "    method_train = arc.methods.SplitConformal(X, Yt, black_box, K, 0.1, n_cal=n_cal, random_state=random_state)\n",
    "    print(\"Done.\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Extract the pre-trained model\n",
    "    black_box_pt = method_train.black_box\n",
    "\n",
    "    # Estimate the contamination process using anchor points\n",
    "    _, X_cal, _, _ = train_test_split(X, Y, test_size=n_cal, random_state=random_state)\n",
    "    p_hat_cal = black_box_pt.predict_proba(X_cal)\n",
    "    if not isinstance(p_hat_cal, np.ndarray):\n",
    "        p_hat_cal = np.asarray(p_hat_cal)\n",
    "    _, K_out = p_hat_cal.shape\n",
    "    assert K_out == K, f\"black_box_pt returned {K_out} classes, expected {K}\"\n",
    "\n",
    "    T_hat = np.zeros((K, K), dtype=float)\n",
    "    x_bar_list = []\n",
    "    for l in range(K):\n",
    "        idx_star = np.argmax(p_hat_cal[:, l])\n",
    "        x_bar_l = X_cal[idx_star]\n",
    "        T_hat[:, l] = p_hat_cal[idx_star, :]\n",
    "\n",
    "        x_bar_list.append(x_bar_l)\n",
    "    \n",
    "\n",
    "    res = pd.DataFrame({})\n",
    "    for alpha in [0.1]:\n",
    "        #for guarantee in ['lab-cond', 'marginal']:\n",
    "        for guarantee in ['marginal']:\n",
    "            print(\"\\nSeeking {:s} coverage at level {:.2f}.\".format(guarantee, 1-alpha))\n",
    "\n",
    "            #if guarantee=='lab-cond':\n",
    "            #    label_conditional = True\n",
    "            #else:\n",
    "            label_conditional = False\n",
    "\n",
    "            # Define a dictionary of methods with their names and corresponding initialization parameters\n",
    "            methods = {\n",
    "                \"Standard\": lambda: arc.methods.SplitConformal(X, Yt, black_box_pt, K, alpha, n_cal=n_cal,\n",
    "                                                               label_conditional=label_conditional, allow_empty=allow_empty,\n",
    "                                                               pre_trained=True, random_state=random_state),\n",
    "\n",
    "                \"Adaptive optimized\": lambda: MarginalLabelNoiseConformal(X, Yt, black_box_pt, K, alpha, n_cal=n_cal,\n",
    "                                                                          epsilon=epsilon, T=T, rho_tilde=rho_tilde_hat,\n",
    "                                                                          allow_empty=allow_empty, method=\"improved\",\n",
    "                                                                          optimized=True, optimistic=False, verbose=False,\n",
    "                                                                          pre_trained=True, random_state=random_state),\n",
    "\n",
    "                \"Adaptive optimized+\": lambda: MarginalLabelNoiseConformal(X, Yt, black_box_pt, K, alpha, n_cal=n_cal,\n",
    "                                                                          epsilon=epsilon, T=T, rho_tilde=rho_tilde_hat,\n",
    "                                                                          allow_empty=allow_empty, method=\"improved\",\n",
    "                                                                          optimized=True, optimistic=True, verbose=False,\n",
    "                                                                          pre_trained=True, random_state=random_state),\n",
    "\n",
    "                \"Asymptotic\": lambda: MarginalLabelNoiseConformal(X, Yt, black_box_pt, K, alpha, n_cal=n_cal,\n",
    "                                                                   epsilon=epsilon, asymptotic_h_start=asymptotic_h_start,\n",
    "                                                                   asymptotic_MC_samples=asymptotic_MC_samples, T=T,\n",
    "                                                                   rho_tilde=rho_tilde_hat, allow_empty=allow_empty,\n",
    "                                                                   method=\"asymptotic\", optimistic=False, verbose=False,\n",
    "                                                                   pre_trained=True, random_state=random_state),\n",
    "\n",
    "                \"Asymptotic+\": lambda: MarginalLabelNoiseConformal(X, Yt, black_box_pt, K, alpha, n_cal=n_cal,\n",
    "                                                                   epsilon=epsilon, asymptotic_h_start=asymptotic_h_start,\n",
    "                                                                   asymptotic_MC_samples=asymptotic_MC_samples, T=T,\n",
    "                                                                   rho_tilde=rho_tilde_hat, allow_empty=allow_empty,\n",
    "                                                                   method=\"asymptotic\", optimistic=True, verbose=False,\n",
    "                                                                   pre_trained=True, random_state=random_state),\n",
    "\n",
    "                \"Adaptive optimized AP\": lambda: MarginalLabelNoiseConformal(X, Yt, black_box_pt, K, alpha, n_cal=n_cal,\n",
    "                                                                          epsilon=epsilon, T=T_hat, rho_tilde=rho_tilde_hat,\n",
    "                                                                          allow_empty=allow_empty, method=\"improved\",\n",
    "                                                                          optimized=True, optimistic=False, verbose=False,\n",
    "                                                                          pre_trained=True, random_state=random_state),\n",
    "\n",
    "                \"Adaptive optimized+ AP\": lambda: MarginalLabelNoiseConformal(X, Yt, black_box_pt, K, alpha, n_cal=n_cal,\n",
    "                                                                          epsilon=epsilon, T=T_hat, rho_tilde=rho_tilde_hat,\n",
    "                                                                          allow_empty=allow_empty, method=\"improved\",\n",
    "                                                                          optimized=True, optimistic=True, verbose=False,\n",
    "                                                                          pre_trained=True, random_state=random_state),\n",
    "\n",
    "                \"Asymptotic AP\": lambda: MarginalLabelNoiseConformal(X, Yt, black_box_pt, K, alpha, n_cal=n_cal,\n",
    "                                                                   epsilon=epsilon, asymptotic_h_start=asymptotic_h_start,\n",
    "                                                                   asymptotic_MC_samples=asymptotic_MC_samples, T=T_hat,\n",
    "                                                                   rho_tilde=rho_tilde_hat, allow_empty=allow_empty,\n",
    "                                                                   method=\"asymptotic\", optimistic=False, verbose=False,\n",
    "                                                                   pre_trained=True, random_state=random_state),\n",
    "\n",
    "                \"Asymptotic+ AP\": lambda: MarginalLabelNoiseConformal(X, Yt, black_box_pt, K, alpha, n_cal=n_cal,\n",
    "                                                                   epsilon=epsilon, asymptotic_h_start=asymptotic_h_start,\n",
    "                                                                   asymptotic_MC_samples=asymptotic_MC_samples, T=T_hat,\n",
    "                                                                   rho_tilde=rho_tilde_hat, allow_empty=allow_empty,\n",
    "                                                                   method=\"asymptotic\", optimistic=True, verbose=False,\n",
    "                                                                   pre_trained=True, random_state=random_state),\n",
    "\n",
    "            }\n",
    "\n",
    "            # Initialize an empty list to store the evaluation results\n",
    "            res_list = []\n",
    "\n",
    "            # Loop through the methods, apply them, and evaluate the results\n",
    "            for method_name, method_func in methods.items():\n",
    "                print(f\"Applying {method_name} method...\", end=' ')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "                # Initialize and apply the method\n",
    "                method = method_func()\n",
    "                predictions = method.predict(X_test)\n",
    "\n",
    "                print(\"Done.\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "                # Evaluate the method\n",
    "                res_new = evaluate_predictions(predictions, X_test, Y_test, K, verbose=False)\n",
    "                res_new['Method'] = method_name\n",
    "                res_new['Guarantee'] = guarantee\n",
    "                res_new['Alpha'] = alpha\n",
    "                res_new['random_state'] = random_state\n",
    "\n",
    "                # Append the result to the results list\n",
    "                res_list.append(res_new)\n",
    "\n",
    "            # Combine all results into a single DataFrame\n",
    "            res = pd.concat(res_list)\n",
    "\n",
    "    print(res)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment in batch 1...\n",
      "\n",
      "Generating data... Done.\n",
      "Generating contaminated labels... Done.\n",
      "Training the predictive model... Done.\n",
      "\n",
      "Seeking marginal coverage at level 0.90.\n",
      "Applying Standard method... Done.\n",
      "Applying Adaptive optimized method... Done.\n",
      "Applying Adaptive optimized+ method... Done.\n",
      "Applying Asymptotic method... Done.\n",
      "Applying Asymptotic+ method... Done.\n",
      "Applying Adaptive optimized AP method... Done.\n",
      "Applying Adaptive optimized+ AP method... Done.\n",
      "Applying Asymptotic AP method... Done.\n",
      "Applying Asymptotic+ AP method... Done.\n",
      "   Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0    0.9235  2.2655  marginal                Standard  marginal    0.1  \\\n",
      "0    0.9085  2.1420  marginal      Adaptive optimized  marginal    0.1   \n",
      "0    0.9085  2.1420  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0    0.9065  2.1320  marginal              Asymptotic  marginal    0.1   \n",
      "0    0.9065  2.1320  marginal             Asymptotic+  marginal    0.1   \n",
      "0    0.9310  2.3535  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0    0.9185  2.2490  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0    0.9175  2.2405  marginal           Asymptotic AP  marginal    0.1   \n",
      "0    0.9175  2.2405  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "   random_state  \n",
      "0             1  \n",
      "0             1  \n",
      "0             1  \n",
      "0             1  \n",
      "0             1  \n",
      "0             1  \n",
      "0             1  \n",
      "0             1  \n",
      "0             1  \n",
      "\n",
      "Running experiment in batch 2...\n",
      "\n",
      "Generating data... Done.\n",
      "Generating contaminated labels... Done.\n",
      "Training the predictive model... Done.\n",
      "\n",
      "Seeking marginal coverage at level 0.90.\n",
      "Applying Standard method... Done.\n",
      "Applying Adaptive optimized method... Done.\n",
      "Applying Adaptive optimized+ method... Done.\n",
      "Applying Asymptotic method... Done.\n",
      "Applying Asymptotic+ method... Done.\n",
      "Applying Adaptive optimized AP method... Done.\n",
      "Applying Adaptive optimized+ AP method... Done.\n",
      "Applying Asymptotic AP method... Done.\n",
      "Applying Asymptotic+ AP method... Done.\n",
      "   Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0    0.9320  2.4145  marginal                Standard  marginal    0.1  \\\n",
      "0    0.9160  2.3055  marginal      Adaptive optimized  marginal    0.1   \n",
      "0    0.9160  2.3055  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0    0.9135  2.2710  marginal              Asymptotic  marginal    0.1   \n",
      "0    0.9135  2.2710  marginal             Asymptotic+  marginal    0.1   \n",
      "0    0.9510  2.6260  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0    0.9260  2.3985  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0    0.9170  2.3240  marginal           Asymptotic AP  marginal    0.1   \n",
      "0    0.9165  2.3205  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "   random_state  \n",
      "0             2  \n",
      "0             2  \n",
      "0             2  \n",
      "0             2  \n",
      "0             2  \n",
      "0             2  \n",
      "0             2  \n",
      "0             2  \n",
      "0             2  \n",
      "\n",
      "Running experiment in batch 3...\n",
      "\n",
      "Generating data... Done.\n",
      "Generating contaminated labels... Done.\n",
      "Training the predictive model... Done.\n",
      "\n",
      "Seeking marginal coverage at level 0.90.\n",
      "Applying Standard method... Done.\n",
      "Applying Adaptive optimized method... Done.\n",
      "Applying Adaptive optimized+ method... Done.\n",
      "Applying Asymptotic method... Done.\n",
      "Applying Asymptotic+ method... Done.\n",
      "Applying Adaptive optimized AP method... Done.\n",
      "Applying Adaptive optimized+ AP method... Done.\n",
      "Applying Asymptotic AP method... Done.\n",
      "Applying Asymptotic+ AP method... Done.\n",
      "   Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0    0.9360  2.4545  marginal                Standard  marginal    0.1  \\\n",
      "0    0.9280  2.3925  marginal      Adaptive optimized  marginal    0.1   \n",
      "0    0.9280  2.3925  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0    0.9235  2.3665  marginal              Asymptotic  marginal    0.1   \n",
      "0    0.9235  2.3665  marginal             Asymptotic+  marginal    0.1   \n",
      "0    0.9585  2.6965  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0    0.9360  2.4475  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0    0.9220  2.3565  marginal           Asymptotic AP  marginal    0.1   \n",
      "0    0.9220  2.3565  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "   random_state  \n",
      "0             3  \n",
      "0             3  \n",
      "0             3  \n",
      "0             3  \n",
      "0             3  \n",
      "0             3  \n",
      "0             3  \n",
      "0             3  \n",
      "0             3  \n",
      "\n",
      "Running experiment in batch 4...\n",
      "\n",
      "Generating data... Done.\n",
      "Generating contaminated labels... Done.\n",
      "Training the predictive model... Done.\n",
      "\n",
      "Seeking marginal coverage at level 0.90.\n",
      "Applying Standard method... Done.\n",
      "Applying Adaptive optimized method... Done.\n",
      "Applying Adaptive optimized+ method... Done.\n",
      "Applying Asymptotic method... Done.\n",
      "Applying Asymptotic+ method... Done.\n",
      "Applying Adaptive optimized AP method... Done.\n",
      "Applying Adaptive optimized+ AP method... Done.\n",
      "Applying Asymptotic AP method... Done.\n",
      "Applying Asymptotic+ AP method... Done.\n",
      "   Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0    0.9375  2.3280  marginal                Standard  marginal    0.1  \\\n",
      "0    0.9255  2.2055  marginal      Adaptive optimized  marginal    0.1   \n",
      "0    0.9260  2.2190  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0    0.9240  2.1920  marginal              Asymptotic  marginal    0.1   \n",
      "0    0.9240  2.1920  marginal             Asymptotic+  marginal    0.1   \n",
      "0    0.9570  2.6460  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0    0.9345  2.3185  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0    0.9320  2.2900  marginal           Asymptotic AP  marginal    0.1   \n",
      "0    0.9320  2.2900  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "   random_state  \n",
      "0             4  \n",
      "0             4  \n",
      "0             4  \n",
      "0             4  \n",
      "0             4  \n",
      "0             4  \n",
      "0             4  \n",
      "0             4  \n",
      "0             4  \n",
      "\n",
      "Running experiment in batch 5...\n",
      "\n",
      "Generating data... Done.\n",
      "Generating contaminated labels... Done.\n",
      "Training the predictive model... Done.\n",
      "\n",
      "Seeking marginal coverage at level 0.90.\n",
      "Applying Standard method... Done.\n",
      "Applying Adaptive optimized method... Done.\n",
      "Applying Adaptive optimized+ method... Done.\n",
      "Applying Asymptotic method... Done.\n",
      "Applying Asymptotic+ method... Done.\n",
      "Applying Adaptive optimized AP method... Done.\n",
      "Applying Adaptive optimized+ AP method... Done.\n",
      "Applying Asymptotic AP method... Done.\n",
      "Applying Asymptotic+ AP method... Done.\n",
      "   Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0    0.9210  2.5705  marginal                Standard  marginal    0.1  \\\n",
      "0    0.9130  2.4910  marginal      Adaptive optimized  marginal    0.1   \n",
      "0    0.9130  2.4910  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0    0.9095  2.4625  marginal              Asymptotic  marginal    0.1   \n",
      "0    0.9095  2.4625  marginal             Asymptotic+  marginal    0.1   \n",
      "0    0.9430  2.7695  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0    0.9215  2.5700  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0    0.9055  2.4350  marginal           Asymptotic AP  marginal    0.1   \n",
      "0    0.9055  2.4350  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "   random_state  \n",
      "0             5  \n",
      "0             5  \n",
      "0             5  \n",
      "0             5  \n",
      "0             5  \n",
      "0             5  \n",
      "0             5  \n",
      "0             5  \n",
      "0             5  \n",
      "\n",
      "Running experiment in batch 6...\n",
      "\n",
      "Generating data... Done.\n",
      "Generating contaminated labels... Done.\n",
      "Training the predictive model... Done.\n",
      "\n",
      "Seeking marginal coverage at level 0.90.\n",
      "Applying Standard method... Done.\n",
      "Applying Adaptive optimized method... Done.\n",
      "Applying Adaptive optimized+ method... Done.\n",
      "Applying Asymptotic method... Done.\n",
      "Applying Asymptotic+ method... Done.\n",
      "Applying Adaptive optimized AP method... Done.\n",
      "Applying Adaptive optimized+ AP method... Done.\n",
      "Applying Asymptotic AP method... Done.\n",
      "Applying Asymptotic+ AP method... Done.\n",
      "   Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0    0.9465  2.5380  marginal                Standard  marginal    0.1  \\\n",
      "0    0.9315  2.4655  marginal      Adaptive optimized  marginal    0.1   \n",
      "0    0.9295  2.4410  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0    0.9275  2.4045  marginal              Asymptotic  marginal    0.1   \n",
      "0    0.9275  2.4045  marginal             Asymptotic+  marginal    0.1   \n",
      "0    0.9600  2.7800  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0    0.9415  2.5410  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0    0.9425  2.5795  marginal           Asymptotic AP  marginal    0.1   \n",
      "0    0.9415  2.5410  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "   random_state  \n",
      "0             6  \n",
      "0             6  \n",
      "0             6  \n",
      "0             6  \n",
      "0             6  \n",
      "0             6  \n",
      "0             6  \n",
      "0             6  \n",
      "0             6  \n",
      "\n",
      "Running experiment in batch 7...\n",
      "\n",
      "Generating data... Done.\n",
      "Generating contaminated labels... Done.\n",
      "Training the predictive model... Done.\n",
      "\n",
      "Seeking marginal coverage at level 0.90.\n",
      "Applying Standard method... Done.\n",
      "Applying Adaptive optimized method... Done.\n",
      "Applying Adaptive optimized+ method... Done.\n",
      "Applying Asymptotic method... Done.\n",
      "Applying Asymptotic+ method... Done.\n",
      "Applying Adaptive optimized AP method... Done.\n",
      "Applying Adaptive optimized+ AP method... Done.\n",
      "Applying Asymptotic AP method... Done.\n",
      "Applying Asymptotic+ AP method... Done.\n",
      "   Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0    0.9325  2.4800  marginal                Standard  marginal    0.1  \\\n",
      "0    0.9250  2.3605  marginal      Adaptive optimized  marginal    0.1   \n",
      "0    0.9250  2.3605  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0    0.9230  2.3510  marginal              Asymptotic  marginal    0.1   \n",
      "0    0.9230  2.3510  marginal             Asymptotic+  marginal    0.1   \n",
      "0    0.9450  2.5685  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0    0.9370  2.4625  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0    0.9390  2.4850  marginal           Asymptotic AP  marginal    0.1   \n",
      "0    0.9370  2.4625  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "   random_state  \n",
      "0             7  \n",
      "0             7  \n",
      "0             7  \n",
      "0             7  \n",
      "0             7  \n",
      "0             7  \n",
      "0             7  \n",
      "0             7  \n",
      "0             7  \n",
      "\n",
      "Running experiment in batch 8...\n",
      "\n",
      "Generating data... Done.\n",
      "Generating contaminated labels... Done.\n",
      "Training the predictive model... Done.\n",
      "\n",
      "Seeking marginal coverage at level 0.90.\n",
      "Applying Standard method... Done.\n",
      "Applying Adaptive optimized method... Done.\n",
      "Applying Adaptive optimized+ method... Done.\n",
      "Applying Asymptotic method... Done.\n",
      "Applying Asymptotic+ method... Done.\n",
      "Applying Adaptive optimized AP method... Done.\n",
      "Applying Adaptive optimized+ AP method... Done.\n",
      "Applying Asymptotic AP method... Done.\n",
      "Applying Asymptotic+ AP method... Done.\n",
      "   Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0    0.9365  2.3845  marginal                Standard  marginal    0.1  \\\n",
      "0    0.9335  2.3465  marginal      Adaptive optimized  marginal    0.1   \n",
      "0    0.9325  2.3355  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0    0.9325  2.3280  marginal              Asymptotic  marginal    0.1   \n",
      "0    0.9325  2.3280  marginal             Asymptotic+  marginal    0.1   \n",
      "0    0.9430  2.4760  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0    0.9370  2.3870  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0    0.9380  2.4105  marginal           Asymptotic AP  marginal    0.1   \n",
      "0    0.9370  2.3870  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "   random_state  \n",
      "0             8  \n",
      "0             8  \n",
      "0             8  \n",
      "0             8  \n",
      "0             8  \n",
      "0             8  \n",
      "0             8  \n",
      "0             8  \n",
      "0             8  \n",
      "\n",
      "Running experiment in batch 9...\n",
      "\n",
      "Generating data... Done.\n",
      "Generating contaminated labels... Done.\n",
      "Training the predictive model... Done.\n",
      "\n",
      "Seeking marginal coverage at level 0.90.\n",
      "Applying Standard method... Done.\n",
      "Applying Adaptive optimized method... Done.\n",
      "Applying Adaptive optimized+ method... Done.\n",
      "Applying Asymptotic method... Done.\n",
      "Applying Asymptotic+ method... Done.\n",
      "Applying Adaptive optimized AP method... Done.\n",
      "Applying Adaptive optimized+ AP method... Done.\n",
      "Applying Asymptotic AP method... Done.\n",
      "Applying Asymptotic+ AP method... Done.\n",
      "   Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0    0.9450  2.5200  marginal                Standard  marginal    0.1  \\\n",
      "0    0.9400  2.4495  marginal      Adaptive optimized  marginal    0.1   \n",
      "0    0.9400  2.4495  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0    0.9360  2.3985  marginal              Asymptotic  marginal    0.1   \n",
      "0    0.9350  2.3950  marginal             Asymptotic+  marginal    0.1   \n",
      "0    0.9620  2.8040  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0    0.9440  2.5300  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0    0.9425  2.4710  marginal           Asymptotic AP  marginal    0.1   \n",
      "0    0.9425  2.4710  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "   random_state  \n",
      "0             9  \n",
      "0             9  \n",
      "0             9  \n",
      "0             9  \n",
      "0             9  \n",
      "0             9  \n",
      "0             9  \n",
      "0             9  \n",
      "0             9  \n",
      "\n",
      "Running experiment in batch 10...\n",
      "\n",
      "Generating data... Done.\n",
      "Generating contaminated labels... Done.\n",
      "Training the predictive model... Done.\n",
      "\n",
      "Seeking marginal coverage at level 0.90.\n",
      "Applying Standard method... Done.\n",
      "Applying Adaptive optimized method... Done.\n",
      "Applying Adaptive optimized+ method... Done.\n",
      "Applying Asymptotic method... Done.\n",
      "Applying Asymptotic+ method... Done.\n",
      "Applying Adaptive optimized AP method... Done.\n",
      "Applying Adaptive optimized+ AP method... Done.\n",
      "Applying Asymptotic AP method... Done.\n",
      "Applying Asymptotic+ AP method... Done.\n",
      "   Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0    0.9155  2.0940  marginal                Standard  marginal    0.1  \\\n",
      "0    0.8840  1.8805  marginal      Adaptive optimized  marginal    0.1   \n",
      "0    0.8840  1.8805  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0    0.8800  1.8660  marginal              Asymptotic  marginal    0.1   \n",
      "0    0.8790  1.8610  marginal             Asymptotic+  marginal    0.1   \n",
      "0    0.9385  2.3175  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0    0.9145  2.0950  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0    0.9035  2.0055  marginal           Asymptotic AP  marginal    0.1   \n",
      "0    0.9080  2.0270  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "   random_state  \n",
      "0            10  \n",
      "0            10  \n",
      "0            10  \n",
      "0            10  \n",
      "0            10  \n",
      "0            10  \n",
      "0            10  \n",
      "0            10  \n",
      "0            10  \n",
      "\n",
      "Preview of results:\n",
      "    Coverage    Size     Label                  Method Guarantee  Alpha   \n",
      "0     0.9235  2.2655  marginal                Standard  marginal    0.1  \\\n",
      "0     0.9085  2.1420  marginal      Adaptive optimized  marginal    0.1   \n",
      "0     0.9085  2.1420  marginal     Adaptive optimized+  marginal    0.1   \n",
      "0     0.9065  2.1320  marginal              Asymptotic  marginal    0.1   \n",
      "0     0.9065  2.1320  marginal             Asymptotic+  marginal    0.1   \n",
      "..       ...     ...       ...                     ...       ...    ...   \n",
      "0     0.8790  1.8610  marginal             Asymptotic+  marginal    0.1   \n",
      "0     0.9385  2.3175  marginal   Adaptive optimized AP  marginal    0.1   \n",
      "0     0.9145  2.0950  marginal  Adaptive optimized+ AP  marginal    0.1   \n",
      "0     0.9035  2.0055  marginal           Asymptotic AP  marginal    0.1   \n",
      "0     0.9080  2.0270  marginal          Asymptotic+ AP  marginal    0.1   \n",
      "\n",
      "    random_state  \n",
      "0              1  \n",
      "0              1  \n",
      "0              1  \n",
      "0              1  \n",
      "0              1  \n",
      "..           ...  \n",
      "0             10  \n",
      "0             10  \n",
      "0             10  \n",
      "0             10  \n",
      "0             10  \n",
      "\n",
      "[90 rows x 7 columns]\n",
      "\n",
      "Summary of results:\n",
      "  Alpha Guarantee                  Method     Label Coverage             \n",
      "                                                        mean       std   \n",
      "0   0.1  marginal      Adaptive optimized  marginal  0.92050  0.016071  \\\n",
      "1   0.1  marginal   Adaptive optimized AP  marginal  0.94890  0.010384   \n",
      "2   0.1  marginal     Adaptive optimized+  marginal  0.92025  0.015861   \n",
      "3   0.1  marginal  Adaptive optimized+ AP  marginal  0.93105  0.010177   \n",
      "4   0.1  marginal              Asymptotic  marginal  0.91760  0.016272   \n",
      "5   0.1  marginal           Asymptotic AP  marginal  0.92595  0.014867   \n",
      "6   0.1  marginal             Asymptotic+  marginal  0.91740  0.016408   \n",
      "7   0.1  marginal          Asymptotic+ AP  marginal  0.92595  0.013797   \n",
      "8   0.1  marginal                Standard  marginal  0.93260  0.010044   \n",
      "\n",
      "      Size           random_state           \n",
      "      mean       std         mean      std  \n",
      "0  2.30390  0.185698          5.5  3.02765  \n",
      "1  2.60375  0.173732          5.5  3.02765  \n",
      "2  2.30170  0.182482          5.5  3.02765  \n",
      "3  2.39990  0.147001          5.5  3.02765  \n",
      "4  2.27720  0.175981          5.5  3.02765  \n",
      "5  2.35975  0.160021          5.5  3.02765  \n",
      "6  2.27635  0.177017          5.5  3.02765  \n",
      "7  2.35310  0.146480          5.5  3.02765  \n",
      "8  2.40495  0.144914          5.5  3.02765  \n",
      "\n",
      "Finished.\n",
      "Results written to results/exp1/synthetic1_p20_K4_signal1_SVC_eps0.1_nu0_uniform_nt5000_nc1000_estnone_seed1.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run all experiments\n",
    "results = pd.DataFrame({})\n",
    "for batch in np.arange(1,batch_size+1):\n",
    "    res = run_experiment(1000*seed+batch-1000)\n",
    "    results = pd.concat([results, res])\n",
    "\n",
    "    # Save results\n",
    "    outfile = \"results/\" + outfile_prefix + \".txt\"\n",
    "    results_out = pd.concat([header,results], axis=1)\n",
    "    results_out.to_csv(outfile, index=False, float_format=\"%.5f\")\n",
    "\n",
    "print(\"\\nPreview of results:\")\n",
    "print(results)\n",
    "sys.stdout.flush()\n",
    "\n",
    "print(\"\\nSummary of results:\")\n",
    "summary = results.groupby(['Alpha', 'Guarantee', 'Method', 'Label']).agg(['mean','std']).reset_index()\n",
    "print(summary)\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "print(\"\\nFinished.\\nResults written to {:s}\\n\".format(outfile))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
